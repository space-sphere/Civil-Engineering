{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T19:18:23.254849400Z",
     "start_time": "2023-11-08T19:18:01.304844600Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from data_pre import data_normalize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "d = pd.read_excel(r\"D:\\program\\pycharm\\model\\Data\\新训练.xlsx\", sheet_name='Sheet2')\n",
    "# X = df.iloc[:, 1:]\n",
    "# y = df.iloc[:, 0]\n",
    "data = data_normalize(d, 'WD')\n",
    "df = data.fillna_by_random()\n",
    "X = df.iloc[:, 1:]\n",
    "y = df.iloc[:, 0]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "aver = X_train.mean(axis=0)\n",
    "std = X_train.std(axis=0)\n",
    "X_train = (X_train-aver)/std\n",
    "X_test = (X_test-aver)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.6451612903225806\n",
      "\n",
      "分类识别报告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       1.00      0.69      0.82        13\n",
      "           3       0.44      0.57      0.50         7\n",
      "           4       0.54      0.88      0.67         8\n",
      "           5       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.65        31\n",
      "   macro avg       0.40      0.43      0.40        31\n",
      "weighted avg       0.66      0.65      0.63        31\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "def train_and_evaluate(clf, X_train, X_test, y_train, y_test):\n",
    "    clf.fit(X_train, y_train)             # 训练\n",
    "\n",
    "    print (\"训练集精度:\")   # 训练集精度\n",
    "    print (clf.score(X_train, y_train))\n",
    "\n",
    "    print (\"\\n测试集精度:\")    # 测试集精度\n",
    "    print (clf.score(X_test, y_test))\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print (\"\\n分类识别报告:\")      # 分类识别报告\n",
    "    print (metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "    # print (\"\\n混淆矩阵:\")\n",
    "    # print (metrics.confusion_matrix(y_test, y_pred))\n",
    "params = {\n",
    "    'n_estimators': 400, # 弱分类器的个数\n",
    "    'max_depth': 2,       # 弱分类器（CART回归树）的最大深度\n",
    "    'min_samples_split': 3, # 分裂内部节点所需的最小样本数\n",
    "    'learning_rate': 0.02,  # 学习率\n",
    "    'loss': 'deviance',\n",
    "    'subsample': 0.8,\n",
    "    'random_state': 1\n",
    "}\n",
    "clf = GradientBoostingClassifier(**params)\n",
    "train_and_evaluate(clf, X_train, X_test, y_train, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T10:08:31.263495800Z",
     "start_time": "2023-11-08T10:08:30.056440600Z"
    }
   },
   "id": "67c378e41ff3e013"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度:\n",
      "0.9333333333333333\n",
      "\n",
      "测试集精度:\n",
      "0.7096774193548387\n",
      "\n",
      "分类识别报告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       1.00      0.62      0.76        13\n",
      "           3       0.71      0.71      0.71         7\n",
      "           4       0.53      1.00      0.70         8\n",
      "           5       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.71        31\n",
      "   macro avg       0.65      0.57      0.57        31\n",
      "weighted avg       0.78      0.71      0.70        31\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "params = {\n",
    "    'n_estimators': 50, # 弱分类器的个数\n",
    "    'max_depth': 3,       # 弱分类器（CART回归树）的最大深度\n",
    "    'min_samples_split': 3, # 分裂内部节点所需的最小样本数\n",
    "    'learning_rate': 0.02,  # 学习率\n",
    "    'loss': 'deviance',\n",
    "    'subsample': 0.8,\n",
    "    'random_state': 1\n",
    "}\n",
    "GBDTClf = GradientBoostingClassifier(**params)\n",
    "from sklearn import metrics\n",
    "def train_and_evaluate(clf, X_train, X_test, y_train, y_test):\n",
    "    clf.fit(X_train, y_train)             # 训练\n",
    "\n",
    "    print (\"训练集精度:\")   # 训练集精度\n",
    "    print (clf.score(X_train, y_train))\n",
    "\n",
    "    print (\"\\n测试集精度:\")    # 测试集精度\n",
    "    print (clf.score(X_test, y_test))\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print (\"\\n分类识别报告:\")      # 分类识别报告\n",
    "    print (metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "    # print (\"\\n混淆矩阵:\")\n",
    "    # print (metrics.confusion_matrix(y_test, y_pred))\n",
    "train_and_evaluate(GBDTClf, X_train, X_test, y_train, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T09:55:58.589980100Z",
     "start_time": "2023-11-08T09:55:58.212020200Z"
    }
   },
   "id": "e5da5afce5f59dd9"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "训练集精度:\n",
      "0.9916666666666667\n",
      "\n",
      "测试集精度:\n",
      "0.7419354838709677\n",
      "==================================================\n",
      "150\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.7741935483870968\n",
      "==================================================\n",
      "175\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.7741935483870968\n",
      "==================================================\n",
      "200\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.7741935483870968\n",
      "==================================================\n",
      "225\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.7741935483870968\n",
      "==================================================\n",
      "250\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.7741935483870968\n",
      "==================================================\n",
      "300\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.7741935483870968\n",
      "==================================================\n",
      "350\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.7741935483870968\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [100, 150, 175, 200, 225, 250, 300, 350]\n",
    "for n in n_estimators:\n",
    "    params = {\n",
    "        'n_estimators': n, # 弱分类器的个数\n",
    "        'max_depth': 3,       # 弱分类器（CART回归树）的最大深度\n",
    "        'min_samples_split': 3, # 分裂内部节点所需的最小样本数\n",
    "        'learning_rate': 0.02,  # 学习率\n",
    "        'loss': 'deviance',\n",
    "        'subsample': 0.8,\n",
    "        'random_state': 1\n",
    "    }\n",
    "    clf = GradientBoostingClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(n)\n",
    "    print (\"训练集精度:\")   # 训练集精度\n",
    "    print (clf.score(X_train, y_train))\n",
    "\n",
    "    print (\"\\n测试集精度:\")    # 测试集精度\n",
    "    print (clf.score(X_test, y_test))\n",
    "    print('=' * 50)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T22:58:45.519226200Z",
     "start_time": "2023-11-07T22:58:39.530392300Z"
    }
   },
   "id": "72d66a461e127a2f"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "训练集精度:\n",
      "0.7833333333333333\n",
      "\n",
      "测试集精度:\n",
      "0.7096774193548387\n",
      "==================================================\n",
      "2\n",
      "训练集精度:\n",
      "0.9583333333333334\n",
      "\n",
      "测试集精度:\n",
      "0.7419354838709677\n",
      "==================================================\n",
      "3\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.7741935483870968\n",
      "==================================================\n",
      "4\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.7741935483870968\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "max_depth = [1, 2, 3, 4]\n",
    "for n in max_depth:\n",
    "    params = {\n",
    "        'n_estimators': 150, # 弱分类器的个数\n",
    "        'max_depth': n,       # 弱分类器（CART回归树）的最大深度\n",
    "        'min_samples_split': 3, # 分裂内部节点所需的最小样本数\n",
    "        'learning_rate': 0.02,  # 学习率\n",
    "        'loss': 'deviance',\n",
    "        'subsample': 0.8,\n",
    "        'random_state': 1\n",
    "    }\n",
    "    clf = GradientBoostingClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(n)\n",
    "    print (\"训练集精度:\")   # 训练集精度\n",
    "    print (clf.score(X_train, y_train))\n",
    "\n",
    "    print (\"\\n测试集精度:\")    # 测试集精度\n",
    "    print (clf.score(X_test, y_test))\n",
    "    print('=' * 50)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T22:59:15.269768200Z",
     "start_time": "2023-11-07T22:59:13.300726Z"
    }
   },
   "id": "b2c9a33ce1b8a493"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.7741935483870968\n",
      "==================================================\n",
      "3\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.7741935483870968\n",
      "==================================================\n",
      "4\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.7741935483870968\n",
      "==================================================\n",
      "5\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.7741935483870968\n",
      "==================================================\n",
      "6\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.7741935483870968\n",
      "==================================================\n",
      "7\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.7741935483870968\n",
      "==================================================\n",
      "8\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.7741935483870968\n",
      "==================================================\n",
      "9\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.7741935483870968\n",
      "==================================================\n",
      "10\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.7741935483870968\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "min_samples_split = [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "for n in min_samples_split:\n",
    "    params = {\n",
    "        'n_estimators': 400, # 弱分类器的个数\n",
    "        'max_depth': 2,       # 弱分类器（CART回归树）的最大深度\n",
    "        'min_samples_split': n, # 分裂内部节点所需的最小样本数\n",
    "        'learning_rate': 0.02,  # 学习率\n",
    "        'loss': 'deviance',\n",
    "        'subsample': 0.8,\n",
    "        'random_state': 1\n",
    "    }\n",
    "    clf = GradientBoostingClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(n)\n",
    "    print (\"训练集精度:\")   # 训练集精度\n",
    "    print (clf.score(X_train, y_train))\n",
    "\n",
    "    print (\"\\n测试集精度:\")    # 测试集精度\n",
    "    print (clf.score(X_test, y_test))\n",
    "    print('=' * 50)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T22:59:48.551189300Z",
     "start_time": "2023-11-07T22:59:37.927307600Z"
    }
   },
   "id": "58ae6836585ca684"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.7741935483870968\n",
      "==================================================\n",
      "0.05\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.7741935483870968\n",
      "==================================================\n",
      "0.01\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.7741935483870968\n",
      "==================================================\n",
      "0.02\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.7741935483870968\n",
      "==================================================\n",
      "0.025\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.7741935483870968\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "learning_rate = [0.01, 0.05, 0.01, 0.02, 0.025]\n",
    "for n in learning_rate:\n",
    "    params = {\n",
    "        'n_estimators': 400, # 弱分类器的个数\n",
    "        'max_depth': 3,       # 弱分类器（CART回归树）的最大深度\n",
    "        'min_samples_split': 3, # 分裂内部节点所需的最小样本数\n",
    "        'learning_rate': n,  # 学习率\n",
    "        'loss': 'deviance',\n",
    "        'subsample': 0.8,\n",
    "        'random_state': 1\n",
    "    }\n",
    "    clf = GradientBoostingClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(n)\n",
    "    print (\"训练集精度:\")   # 训练集精度\n",
    "    print (clf.score(X_train, y_train))\n",
    "\n",
    "    print (\"\\n测试集精度:\")    # 测试集精度\n",
    "    print (clf.score(X_test, y_test))\n",
    "    print('=' * 50)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T23:00:45.813208300Z",
     "start_time": "2023-11-07T23:00:38.992481800Z"
    }
   },
   "id": "9db1afbd835141e2"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "训练集精度:\n",
      "0.9\n",
      "\n",
      "测试集精度:\n",
      "0.6451612903225806\n",
      "==================================================\n",
      "0.2\n",
      "训练集精度:\n",
      "0.975\n",
      "\n",
      "测试集精度:\n",
      "0.6451612903225806\n",
      "==================================================\n",
      "0.5\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.7741935483870968\n",
      "==================================================\n",
      "0.8\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.7741935483870968\n",
      "==================================================\n",
      "1.0\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.7741935483870968\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "subsample = [0.1, 0.2, 0.5, 0.8, 1.0]\n",
    "for n in subsample:\n",
    "    params = {\n",
    "        'n_estimators': 400, # 弱分类器的个数\n",
    "        'max_depth': 2,       # 弱分类器（CART回归树）的最大深度\n",
    "        'min_samples_split': 3, # 分裂内部节点所需的最小样本数\n",
    "        'learning_rate': 0.02,  # 学习率\n",
    "        'loss': 'deviance',\n",
    "        'subsample': n,\n",
    "        'random_state': 1\n",
    "    }\n",
    "    clf = GradientBoostingClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(n)\n",
    "    print (\"训练集精度:\")   # 训练集精度\n",
    "    print (clf.score(X_train, y_train))\n",
    "\n",
    "    print (\"\\n测试集精度:\")    # 测试集精度\n",
    "    print (clf.score(X_test, y_test))\n",
    "    print('=' * 50)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T23:01:36.836726Z",
     "start_time": "2023-11-07T23:01:31.347471300Z"
    }
   },
   "id": "fd0d0ec43af9b976"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.7741935483870968\n",
      "==================================================\n",
      "2\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.7741935483870968\n",
      "==================================================\n",
      "3\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.7741935483870968\n",
      "==================================================\n",
      "4\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.7741935483870968\n",
      "==================================================\n",
      "5\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.7741935483870968\n",
      "==================================================\n",
      "6\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.7741935483870968\n",
      "==================================================\n",
      "7\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.7741935483870968\n",
      "==================================================\n",
      "8\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.7741935483870968\n",
      "==================================================\n",
      "9\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.7741935483870968\n",
      "==================================================\n",
      "10\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.7741935483870968\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "random_state = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "for n in random_state:\n",
    "    params = {\n",
    "        'n_estimators': 400, # 弱分类器的个数\n",
    "        'max_depth': 2,       # 弱分类器（CART回归树）的最大深度\n",
    "        'min_samples_split': 3, # 分裂内部节点所需的最小样本数\n",
    "        'learning_rate': 0.02,  # 学习率\n",
    "        'loss': 'deviance',\n",
    "        'subsample': 0.8,\n",
    "        'random_state': n\n",
    "    }\n",
    "    clf = GradientBoostingClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(n)\n",
    "    print (\"训练集精度:\")   # 训练集精度\n",
    "    print (clf.score(X_train, y_train))\n",
    "\n",
    "    print (\"\\n测试集精度:\")    # 测试集精度\n",
    "    print (clf.score(X_test, y_test))\n",
    "    print('=' * 50)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T22:47:28.356712700Z",
     "start_time": "2023-11-07T22:47:16.568044600Z"
    }
   },
   "id": "ff715d8cb1a07985"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.6774193548387096\n",
      "\n",
      "分类识别报告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.90      0.69      0.78        13\n",
      "           3       0.60      0.86      0.71         7\n",
      "           4       0.55      0.75      0.63         8\n",
      "           5       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.68        31\n",
      "   macro avg       0.41      0.46      0.42        31\n",
      "weighted avg       0.65      0.68      0.65        31\n"
     ]
    }
   ],
   "source": [
    "def train_and_evaluate(clf, X_train, X_test, y_train, y_test):\n",
    "    clf.fit(X_train, y_train)             # 训练\n",
    "\n",
    "    print (\"训练集精度:\")   # 训练集精度\n",
    "    print (clf.score(X_train, y_train))\n",
    "\n",
    "    print (\"\\n测试集精度:\")    # 测试集精度\n",
    "    print (clf.score(X_test, y_test))\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print (\"\\n分类识别报告:\")      # 分类识别报告\n",
    "    print (metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "    # print (\"\\n混淆矩阵:\")\n",
    "    # print (metrics.confusion_matrix(y_test, y_pred))\n",
    "params = {\n",
    "    'n_estimators': 400, # 弱分类器的个数\n",
    "    'max_depth': 2,       # 弱分类器（CART回归树）的最大深度\n",
    "    'min_samples_split': 3, # 分裂内部节点所需的最小样本数\n",
    "    'learning_rate': 0.02,  # 学习率\n",
    "    'loss': 'deviance',\n",
    "    'subsample': 0.8,\n",
    "    'random_state': 1\n",
    "}\n",
    "clf = GradientBoostingClassifier(**params)\n",
    "train_and_evaluate(clf, X_train, X_test, y_train, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T09:57:48.837512300Z",
     "start_time": "2023-11-08T09:57:47.525346600Z"
    }
   },
   "id": "7cd3424a8089645d"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "          WLC       WLA       WIA        TD        TI       UCS       MTL  \\\n85   0.654106  0.010462  0.633426  1.054838  0.204604  0.176290 -0.469115   \n112  1.536047  1.331419 -0.839205  2.008446  1.270762  0.993309 -0.829197   \n10   1.536047  1.019210  2.244264  2.338464  2.473987 -1.546092  1.405288   \n133 -1.109776 -0.970003 -0.572821  0.044945 -1.389334 -0.152771  0.223921   \n53   0.654106 -0.401208  0.116329 -0.038470  0.057645  0.268190 -0.469115   \n61   2.417989  1.177907  2.554522  2.085935  1.415601 -1.664673  0.080875   \n63   1.536047  0.043458  0.213480 -0.288422 -0.038444  0.074310  0.196792   \n68  -0.227835 -0.020963  1.294685  0.904646  1.104726 -0.283210  0.270781   \n39   0.654106  0.010462  0.633426  1.054838  0.204604  0.176290  0.591403   \n56   1.536047  1.019210  2.244264  2.338464  2.473987 -1.546092 -0.876057   \n67   1.536047  0.291717  1.896398  2.196002  1.952566 -0.945482 -1.024036   \n143  1.536047  1.161723  0.154249 -0.109039 -0.650442 -1.595896  0.366968   \n82  -1.109776 -0.970003 -0.892795 -1.025393  1.952566  0.731246  0.418761   \n1   -1.109776  0.616968  2.557656  2.076732  2.410399 -1.252013 -1.948906   \n19  -0.227835 -0.926008 -1.231259 -1.478546 -1.171722  1.679298  1.257309   \n144  0.654106  0.452771  0.476103 -0.378537 -0.502636 -1.643328 -0.481446   \n121  1.536047  3.208444 -0.580343 -0.879067 -0.207022 -0.120162  0.366968   \n38  -1.109776 -0.930722 -1.312741 -0.966863 -1.153352  1.780091  1.158656   \n21   1.536047  0.291717  1.896398  2.196002  1.952566 -0.945482 -0.765073   \n35  -1.109776 -0.970003 -0.924134 -1.195463 -1.053025  1.424350  0.344771   \n91  -0.227835  0.708101 -0.996215 -0.708444 -0.872152  0.588950 -1.948906   \n145 -0.227835 -0.902439 -0.149428 -0.532558  0.236256  0.121150 -0.819332   \n58  -0.227835  0.048172 -0.197064  0.019692  0.388302  0.371355 -1.670212   \n24   0.654106  0.024603  1.608077  0.808568  0.856027  0.198820  0.246118   \n142 -0.227835  1.350274  0.415932 -0.417042 -0.945914 -1.020188 -0.261944   \n2    0.654106  0.428417  1.893264  0.763289  1.244620  0.040515 -0.222483   \n118 -0.227835  0.605183 -0.398575 -1.264044 -0.650442 -1.607754 -0.363063   \n76  -0.227835 -0.673035 -0.306751 -0.639238 -0.210838  1.068608  1.133993   \n79  -1.109776 -0.503339 -0.225269 -0.376402 -0.460950  1.070387  0.246118   \n90   1.536047  0.268148  0.746248  0.727582 -0.205185  0.493493 -0.049840   \n59  -1.109776 -0.567761 -0.989947 -0.900970 -0.503342  0.850420 -0.876057   \n\n           TN       ATI       TBD  WD  \n85  -1.499208 -0.583975  0.648233   3  \n112  0.923754 -0.215357 -0.112762   2  \n10   0.654536 -0.483921  1.944304   4  \n133  0.789145 -0.300929 -0.231668   5  \n53  -1.768426  1.417096 -1.075897   3  \n61  -0.153118 -0.425996 -0.731071   4  \n63   0.385318  0.785179 -1.194802   3  \n68  -0.422336 -0.320676 -0.576494   2  \n39  -0.691554 -0.373336  0.029925   3  \n56  -0.153118 -0.731422 -0.005747   4  \n67   0.385318 -0.836742  1.290323   2  \n143 -0.960772 -0.483921 -0.873757   4  \n82   1.192972 -0.836742  0.743358   2  \n1   -2.037644  1.680395 -2.157937   4  \n19   1.462190 -0.952593  1.658930   2  \n144  1.798713 -0.228521 -0.231668   5  \n121 -2.037644 -0.425996  1.314104   4  \n38   0.923754 -0.899934  1.314104   2  \n21  -2.306862  1.733055 -2.086594   2  \n35  -0.153118 -0.215357 -0.077090   2  \n91  -0.691554  1.785715 -0.731071   4  \n145 -0.960772 -0.552379 -1.551519   4  \n58  -0.422336 -0.847274  1.884851   2  \n24   0.385318 -0.004717  0.624452   2  \n142 -0.153118 -0.583975  0.029925   3  \n2    0.116100  0.469220 -1.920126   3  \n118 -3.383733  2.364972  0.386641   1  \n76   0.385318 -0.836742 -0.576494   2  \n79  -0.422336 -0.847274 -0.029528   2  \n90  -1.499208  0.469220 -1.408832   3  \n59   1.462190 -0.741954  1.409229   2  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>WLC</th>\n      <th>WLA</th>\n      <th>WIA</th>\n      <th>TD</th>\n      <th>TI</th>\n      <th>UCS</th>\n      <th>MTL</th>\n      <th>TN</th>\n      <th>ATI</th>\n      <th>TBD</th>\n      <th>WD</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>85</th>\n      <td>0.654106</td>\n      <td>0.010462</td>\n      <td>0.633426</td>\n      <td>1.054838</td>\n      <td>0.204604</td>\n      <td>0.176290</td>\n      <td>-0.469115</td>\n      <td>-1.499208</td>\n      <td>-0.583975</td>\n      <td>0.648233</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>112</th>\n      <td>1.536047</td>\n      <td>1.331419</td>\n      <td>-0.839205</td>\n      <td>2.008446</td>\n      <td>1.270762</td>\n      <td>0.993309</td>\n      <td>-0.829197</td>\n      <td>0.923754</td>\n      <td>-0.215357</td>\n      <td>-0.112762</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1.536047</td>\n      <td>1.019210</td>\n      <td>2.244264</td>\n      <td>2.338464</td>\n      <td>2.473987</td>\n      <td>-1.546092</td>\n      <td>1.405288</td>\n      <td>0.654536</td>\n      <td>-0.483921</td>\n      <td>1.944304</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>133</th>\n      <td>-1.109776</td>\n      <td>-0.970003</td>\n      <td>-0.572821</td>\n      <td>0.044945</td>\n      <td>-1.389334</td>\n      <td>-0.152771</td>\n      <td>0.223921</td>\n      <td>0.789145</td>\n      <td>-0.300929</td>\n      <td>-0.231668</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>0.654106</td>\n      <td>-0.401208</td>\n      <td>0.116329</td>\n      <td>-0.038470</td>\n      <td>0.057645</td>\n      <td>0.268190</td>\n      <td>-0.469115</td>\n      <td>-1.768426</td>\n      <td>1.417096</td>\n      <td>-1.075897</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>2.417989</td>\n      <td>1.177907</td>\n      <td>2.554522</td>\n      <td>2.085935</td>\n      <td>1.415601</td>\n      <td>-1.664673</td>\n      <td>0.080875</td>\n      <td>-0.153118</td>\n      <td>-0.425996</td>\n      <td>-0.731071</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>1.536047</td>\n      <td>0.043458</td>\n      <td>0.213480</td>\n      <td>-0.288422</td>\n      <td>-0.038444</td>\n      <td>0.074310</td>\n      <td>0.196792</td>\n      <td>0.385318</td>\n      <td>0.785179</td>\n      <td>-1.194802</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>-0.227835</td>\n      <td>-0.020963</td>\n      <td>1.294685</td>\n      <td>0.904646</td>\n      <td>1.104726</td>\n      <td>-0.283210</td>\n      <td>0.270781</td>\n      <td>-0.422336</td>\n      <td>-0.320676</td>\n      <td>-0.576494</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>0.654106</td>\n      <td>0.010462</td>\n      <td>0.633426</td>\n      <td>1.054838</td>\n      <td>0.204604</td>\n      <td>0.176290</td>\n      <td>0.591403</td>\n      <td>-0.691554</td>\n      <td>-0.373336</td>\n      <td>0.029925</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>1.536047</td>\n      <td>1.019210</td>\n      <td>2.244264</td>\n      <td>2.338464</td>\n      <td>2.473987</td>\n      <td>-1.546092</td>\n      <td>-0.876057</td>\n      <td>-0.153118</td>\n      <td>-0.731422</td>\n      <td>-0.005747</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>1.536047</td>\n      <td>0.291717</td>\n      <td>1.896398</td>\n      <td>2.196002</td>\n      <td>1.952566</td>\n      <td>-0.945482</td>\n      <td>-1.024036</td>\n      <td>0.385318</td>\n      <td>-0.836742</td>\n      <td>1.290323</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>143</th>\n      <td>1.536047</td>\n      <td>1.161723</td>\n      <td>0.154249</td>\n      <td>-0.109039</td>\n      <td>-0.650442</td>\n      <td>-1.595896</td>\n      <td>0.366968</td>\n      <td>-0.960772</td>\n      <td>-0.483921</td>\n      <td>-0.873757</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>-1.109776</td>\n      <td>-0.970003</td>\n      <td>-0.892795</td>\n      <td>-1.025393</td>\n      <td>1.952566</td>\n      <td>0.731246</td>\n      <td>0.418761</td>\n      <td>1.192972</td>\n      <td>-0.836742</td>\n      <td>0.743358</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-1.109776</td>\n      <td>0.616968</td>\n      <td>2.557656</td>\n      <td>2.076732</td>\n      <td>2.410399</td>\n      <td>-1.252013</td>\n      <td>-1.948906</td>\n      <td>-2.037644</td>\n      <td>1.680395</td>\n      <td>-2.157937</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>-0.227835</td>\n      <td>-0.926008</td>\n      <td>-1.231259</td>\n      <td>-1.478546</td>\n      <td>-1.171722</td>\n      <td>1.679298</td>\n      <td>1.257309</td>\n      <td>1.462190</td>\n      <td>-0.952593</td>\n      <td>1.658930</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>144</th>\n      <td>0.654106</td>\n      <td>0.452771</td>\n      <td>0.476103</td>\n      <td>-0.378537</td>\n      <td>-0.502636</td>\n      <td>-1.643328</td>\n      <td>-0.481446</td>\n      <td>1.798713</td>\n      <td>-0.228521</td>\n      <td>-0.231668</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>121</th>\n      <td>1.536047</td>\n      <td>3.208444</td>\n      <td>-0.580343</td>\n      <td>-0.879067</td>\n      <td>-0.207022</td>\n      <td>-0.120162</td>\n      <td>0.366968</td>\n      <td>-2.037644</td>\n      <td>-0.425996</td>\n      <td>1.314104</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>-1.109776</td>\n      <td>-0.930722</td>\n      <td>-1.312741</td>\n      <td>-0.966863</td>\n      <td>-1.153352</td>\n      <td>1.780091</td>\n      <td>1.158656</td>\n      <td>0.923754</td>\n      <td>-0.899934</td>\n      <td>1.314104</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>1.536047</td>\n      <td>0.291717</td>\n      <td>1.896398</td>\n      <td>2.196002</td>\n      <td>1.952566</td>\n      <td>-0.945482</td>\n      <td>-0.765073</td>\n      <td>-2.306862</td>\n      <td>1.733055</td>\n      <td>-2.086594</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>-1.109776</td>\n      <td>-0.970003</td>\n      <td>-0.924134</td>\n      <td>-1.195463</td>\n      <td>-1.053025</td>\n      <td>1.424350</td>\n      <td>0.344771</td>\n      <td>-0.153118</td>\n      <td>-0.215357</td>\n      <td>-0.077090</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>-0.227835</td>\n      <td>0.708101</td>\n      <td>-0.996215</td>\n      <td>-0.708444</td>\n      <td>-0.872152</td>\n      <td>0.588950</td>\n      <td>-1.948906</td>\n      <td>-0.691554</td>\n      <td>1.785715</td>\n      <td>-0.731071</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>-0.227835</td>\n      <td>-0.902439</td>\n      <td>-0.149428</td>\n      <td>-0.532558</td>\n      <td>0.236256</td>\n      <td>0.121150</td>\n      <td>-0.819332</td>\n      <td>-0.960772</td>\n      <td>-0.552379</td>\n      <td>-1.551519</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>-0.227835</td>\n      <td>0.048172</td>\n      <td>-0.197064</td>\n      <td>0.019692</td>\n      <td>0.388302</td>\n      <td>0.371355</td>\n      <td>-1.670212</td>\n      <td>-0.422336</td>\n      <td>-0.847274</td>\n      <td>1.884851</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0.654106</td>\n      <td>0.024603</td>\n      <td>1.608077</td>\n      <td>0.808568</td>\n      <td>0.856027</td>\n      <td>0.198820</td>\n      <td>0.246118</td>\n      <td>0.385318</td>\n      <td>-0.004717</td>\n      <td>0.624452</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>142</th>\n      <td>-0.227835</td>\n      <td>1.350274</td>\n      <td>0.415932</td>\n      <td>-0.417042</td>\n      <td>-0.945914</td>\n      <td>-1.020188</td>\n      <td>-0.261944</td>\n      <td>-0.153118</td>\n      <td>-0.583975</td>\n      <td>0.029925</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.654106</td>\n      <td>0.428417</td>\n      <td>1.893264</td>\n      <td>0.763289</td>\n      <td>1.244620</td>\n      <td>0.040515</td>\n      <td>-0.222483</td>\n      <td>0.116100</td>\n      <td>0.469220</td>\n      <td>-1.920126</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>118</th>\n      <td>-0.227835</td>\n      <td>0.605183</td>\n      <td>-0.398575</td>\n      <td>-1.264044</td>\n      <td>-0.650442</td>\n      <td>-1.607754</td>\n      <td>-0.363063</td>\n      <td>-3.383733</td>\n      <td>2.364972</td>\n      <td>0.386641</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>-0.227835</td>\n      <td>-0.673035</td>\n      <td>-0.306751</td>\n      <td>-0.639238</td>\n      <td>-0.210838</td>\n      <td>1.068608</td>\n      <td>1.133993</td>\n      <td>0.385318</td>\n      <td>-0.836742</td>\n      <td>-0.576494</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>-1.109776</td>\n      <td>-0.503339</td>\n      <td>-0.225269</td>\n      <td>-0.376402</td>\n      <td>-0.460950</td>\n      <td>1.070387</td>\n      <td>0.246118</td>\n      <td>-0.422336</td>\n      <td>-0.847274</td>\n      <td>-0.029528</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>1.536047</td>\n      <td>0.268148</td>\n      <td>0.746248</td>\n      <td>0.727582</td>\n      <td>-0.205185</td>\n      <td>0.493493</td>\n      <td>-0.049840</td>\n      <td>-1.499208</td>\n      <td>0.469220</td>\n      <td>-1.408832</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>-1.109776</td>\n      <td>-0.567761</td>\n      <td>-0.989947</td>\n      <td>-0.900970</td>\n      <td>-0.503342</td>\n      <td>0.850420</td>\n      <td>-0.876057</td>\n      <td>1.462190</td>\n      <td>-0.741954</td>\n      <td>1.409229</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([X_test, y_test], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T23:03:17.345397300Z",
     "start_time": "2023-11-07T23:03:17.314132700Z"
    }
   },
   "id": "44d677d2a5d092b"
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "# X_train[y_test != y_pred]\n",
    "y_pred = pd.DataFrame(y_pred)\n",
    "y_pred.index=y_test.index\n",
    "df_ = pd.concat([X_test, y_pred, y_test], axis=1)\n",
    "# pd.concat([X_test[y_test!=y_pred], y_pred[y_test!=y_pred], y_test[y_test!=y_pred]], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T23:34:09.017432800Z",
     "start_time": "2023-11-07T23:34:08.986168300Z"
    }
   },
   "id": "1409d2564a438141"
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "     WD  WLC     WLA     WIA       TD      TI    UCS    MTL    TN   ATI    TBD\n85    3    3   6.240   6.210   71.360  11.280  34.29    NaN   NaN   NaN    NaN\n112   2    4  14.647   1.511   97.265  18.825  48.07  0.954   NaN   NaN  192.0\n133   5    1   0.000   2.361   43.926   0.000  28.74  1.381   NaN   NaN  182.0\n39    3    3   6.240   6.210   71.360  11.280  34.29  1.530  12.0  0.16  204.0\n21    2    4   8.030  10.240  102.360  23.650  15.37  0.980   6.0  0.56   26.0\n142   3    2  14.767   5.516   31.376   3.138  14.11    NaN   NaN   NaN    NaN\n118   1    2  10.025   2.917    8.367   5.229   4.20  1.143   NaN   NaN  234.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>WD</th>\n      <th>WLC</th>\n      <th>WLA</th>\n      <th>WIA</th>\n      <th>TD</th>\n      <th>TI</th>\n      <th>UCS</th>\n      <th>MTL</th>\n      <th>TN</th>\n      <th>ATI</th>\n      <th>TBD</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>85</th>\n      <td>3</td>\n      <td>3</td>\n      <td>6.240</td>\n      <td>6.210</td>\n      <td>71.360</td>\n      <td>11.280</td>\n      <td>34.29</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>112</th>\n      <td>2</td>\n      <td>4</td>\n      <td>14.647</td>\n      <td>1.511</td>\n      <td>97.265</td>\n      <td>18.825</td>\n      <td>48.07</td>\n      <td>0.954</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>192.0</td>\n    </tr>\n    <tr>\n      <th>133</th>\n      <td>5</td>\n      <td>1</td>\n      <td>0.000</td>\n      <td>2.361</td>\n      <td>43.926</td>\n      <td>0.000</td>\n      <td>28.74</td>\n      <td>1.381</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>182.0</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>3</td>\n      <td>3</td>\n      <td>6.240</td>\n      <td>6.210</td>\n      <td>71.360</td>\n      <td>11.280</td>\n      <td>34.29</td>\n      <td>1.530</td>\n      <td>12.0</td>\n      <td>0.16</td>\n      <td>204.0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>2</td>\n      <td>4</td>\n      <td>8.030</td>\n      <td>10.240</td>\n      <td>102.360</td>\n      <td>23.650</td>\n      <td>15.37</td>\n      <td>0.980</td>\n      <td>6.0</td>\n      <td>0.56</td>\n      <td>26.0</td>\n    </tr>\n    <tr>\n      <th>142</th>\n      <td>3</td>\n      <td>2</td>\n      <td>14.767</td>\n      <td>5.516</td>\n      <td>31.376</td>\n      <td>3.138</td>\n      <td>14.11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>118</th>\n      <td>1</td>\n      <td>2</td>\n      <td>10.025</td>\n      <td>2.917</td>\n      <td>8.367</td>\n      <td>5.229</td>\n      <td>4.20</td>\n      <td>1.143</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>234.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.loc[df_[df_[0] != df_['WD']].index.tolist()]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T23:39:45.326076200Z",
     "start_time": "2023-11-07T23:39:45.310450300Z"
    }
   },
   "id": "fd85574fdb2201fd"
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 7\n",
      "2 13\n",
      "4 8\n",
      "5 2\n",
      "1 1\n"
     ]
    }
   ],
   "source": [
    "for i in df_['WD'].unique():\n",
    "    n = df_[df_['WD'] == i]['WD'].count()\n",
    "    print(i, n, sep=' ')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T23:50:01.312701500Z",
     "start_time": "2023-11-07T23:50:01.302192200Z"
    }
   },
   "id": "e48e8bc1b9f8eb48"
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "data": {
      "text/plain": "array([3, 2, 4, 5, 1], dtype=int64)"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_['WD'].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T23:49:45.339438500Z",
     "start_time": "2023-11-07T23:49:45.308184Z"
    }
   },
   "id": "68574918c6aea74e"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "array([-1.10977591,  1.53604745, -0.22783479,  2.41798858,  0.65410633])"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['WLC'].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T23:19:25.712386800Z",
     "start_time": "2023-11-07T23:19:25.696760300Z"
    }
   },
   "id": "d82b4551b5e6e2cf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "594b642de0fd8da7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
