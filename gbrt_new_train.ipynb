{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T21:17:52.268923Z",
     "start_time": "2023-11-08T21:17:52.143502100Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from data_pre import data_normalize\n",
    "import warnings\n",
    "from sklearn import metrics\n",
    "warnings.filterwarnings('ignore')\n",
    "d = pd.read_excel(r\"D:\\program\\pycharm\\model\\Data\\土木预测训练.xlsx\", sheet_name='Sheet1')\n",
    "# X = df.iloc[:, 1:]\n",
    "# y = df.iloc[:, 0]\n",
    "data = data_normalize(d, 'WD')\n",
    "df = data.fillna_by_random()\n",
    "X = df.iloc[:, 1:]\n",
    "y = df.iloc[:, 0]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "aver = X_train.mean(axis=0)\n",
    "std = X_train.std(axis=0)\n",
    "X_train = (X_train-aver)/std\n",
    "X_test = (X_test-aver)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "     WD  WLC  WLA  WIA  TD   TI  UCS  MTL    TN   ATI  TBD\n0     4    4    3    2   2  2.0  2.0  5.0  5.00  1.00  3.0\n1     4    4    3    2   2  2.0  2.0  5.0  5.00  1.00  3.0\n2     2    1    1    1   1  2.0  4.0  5.0  5.00  1.00  5.0\n3     2    4    3    1   3  4.0  4.0  3.0  5.00  1.00  3.0\n4     4    4    3    2   2  2.0  2.0  5.0  5.00  1.00  3.0\n..   ..  ...  ...  ...  ..  ...  ...  ...   ...   ...  ...\n169   3    4    2    3   3  2.0  3.0  4.0  3.00  4.00  2.0\n170   5    3    2    3   2  2.0  1.0  4.0  6.25  1.25  3.0\n171   5    3    2    3   2  2.0  1.0  4.0  6.25  1.25  3.0\n172   5    3    2    3   2  2.0  1.0  4.0  6.25  1.25  3.0\n173   1    1    1    1   1  1.0  4.0  1.0  1.00  5.00  1.0\n\n[174 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>WD</th>\n      <th>WLC</th>\n      <th>WLA</th>\n      <th>WIA</th>\n      <th>TD</th>\n      <th>TI</th>\n      <th>UCS</th>\n      <th>MTL</th>\n      <th>TN</th>\n      <th>ATI</th>\n      <th>TBD</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>5.00</td>\n      <td>1.00</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>5.00</td>\n      <td>1.00</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>5.00</td>\n      <td>1.00</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>4</td>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>5.00</td>\n      <td>1.00</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>5.00</td>\n      <td>1.00</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>169</th>\n      <td>3</td>\n      <td>4</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.00</td>\n      <td>4.00</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>170</th>\n      <td>5</td>\n      <td>3</td>\n      <td>2</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>6.25</td>\n      <td>1.25</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>171</th>\n      <td>5</td>\n      <td>3</td>\n      <td>2</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>6.25</td>\n      <td>1.25</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>172</th>\n      <td>5</td>\n      <td>3</td>\n      <td>2</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>6.25</td>\n      <td>1.25</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>173</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>1.00</td>\n      <td>5.00</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>174 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T19:58:00.363079400Z",
     "start_time": "2023-11-08T19:58:00.331823700Z"
    }
   },
   "id": "463147afa0c88b0f"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "     WD  WLC  WLA  WIA  TD   TI  UCS  MTL   TN  ATI  TBD\n0     4    4    3    2   2  2.0  2.0  5.0  5.0  1.0  3.0\n1     4    4    3    2   2  2.0  2.0  5.0  5.0  1.0  3.0\n2     2    1    1    1   1  2.0  4.0  5.0  5.0  1.0  5.0\n3     2    4    3    1   3  4.0  4.0  3.0  NaN  NaN  3.0\n4     4    4    3    2   2  2.0  2.0  5.0  5.0  1.0  3.0\n..   ..  ...  ...  ...  ..  ...  ...  ...  ...  ...  ...\n169   3    4    2    3   3  2.0  3.0  NaN  NaN  NaN  NaN\n170   5    3    2    3   2  2.0  1.0  NaN  NaN  NaN  NaN\n171   5    3    2    3   2  2.0  1.0  4.0  NaN  NaN  3.0\n172   5    3    2    3   2  2.0  1.0  4.0  NaN  NaN  3.0\n173   1    1    1    1   1  1.0  4.0  1.0  1.0  5.0  1.0\n\n[174 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>WD</th>\n      <th>WLC</th>\n      <th>WLA</th>\n      <th>WIA</th>\n      <th>TD</th>\n      <th>TI</th>\n      <th>UCS</th>\n      <th>MTL</th>\n      <th>TN</th>\n      <th>ATI</th>\n      <th>TBD</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>4</td>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>169</th>\n      <td>3</td>\n      <td>4</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>170</th>\n      <td>5</td>\n      <td>3</td>\n      <td>2</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>171</th>\n      <td>5</td>\n      <td>3</td>\n      <td>2</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>172</th>\n      <td>5</td>\n      <td>3</td>\n      <td>2</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>173</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>174 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T19:58:01.149030600Z",
     "start_time": "2023-11-08T19:58:01.117989500Z"
    }
   },
   "id": "957973577679fe9c"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "          WLC       WLA       WIA        TD        TI       UCS       MTL  \\\n60   0.191998 -1.274739 -1.290775 -0.185449 -0.077791 -0.745462 -1.869691   \n55  -0.728267  0.954050 -1.290775 -0.185449 -1.429403  1.121551  0.653484   \n24   1.112263  0.954050 -0.147987 -0.185449 -0.077791 -0.745462  0.653484   \n58   0.191998  0.954050 -0.147987 -0.185449 -0.077791  1.121551 -3.131278   \n117  1.112263  0.954050 -0.147987 -0.185449 -0.077791 -0.745462  0.653484   \n..        ...       ...       ...       ...       ...       ...       ...   \n113 -1.648532 -1.274739 -1.290775 -1.357153 -1.429403  2.055057 -0.608103   \n64  -1.648532 -1.274739 -1.290775 -1.357153 -1.429403  2.055057  0.653484   \n15  -1.648532 -1.274739 -0.147987 -0.185449 -0.077791  1.121551  0.653484   \n125  0.191998  0.954050 -0.147987 -0.185449 -0.077791 -0.745462  0.653484   \n9    1.112263  0.954050 -0.147987 -0.185449 -0.077791 -0.745462  0.653484   \n\n          TN       ATI       TBD  \n60  -0.44892  3.111978 -1.161063  \n55   0.51852 -0.526844  0.807080  \n24   0.51852 -0.526844 -0.176991  \n58   0.51852 -0.526844  0.807080  \n117  0.51852 -0.526844 -0.176991  \n..       ...       ...       ...  \n113  0.51852 -0.526844  0.807080  \n64   0.51852  0.382862  0.807080  \n15   0.51852 -0.526844  1.791152  \n125  0.51852 -0.526844 -0.176991  \n9    0.51852 -0.526844 -0.176991  \n\n[139 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>WLC</th>\n      <th>WLA</th>\n      <th>WIA</th>\n      <th>TD</th>\n      <th>TI</th>\n      <th>UCS</th>\n      <th>MTL</th>\n      <th>TN</th>\n      <th>ATI</th>\n      <th>TBD</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>60</th>\n      <td>0.191998</td>\n      <td>-1.274739</td>\n      <td>-1.290775</td>\n      <td>-0.185449</td>\n      <td>-0.077791</td>\n      <td>-0.745462</td>\n      <td>-1.869691</td>\n      <td>-0.44892</td>\n      <td>3.111978</td>\n      <td>-1.161063</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>-0.728267</td>\n      <td>0.954050</td>\n      <td>-1.290775</td>\n      <td>-0.185449</td>\n      <td>-1.429403</td>\n      <td>1.121551</td>\n      <td>0.653484</td>\n      <td>0.51852</td>\n      <td>-0.526844</td>\n      <td>0.807080</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>1.112263</td>\n      <td>0.954050</td>\n      <td>-0.147987</td>\n      <td>-0.185449</td>\n      <td>-0.077791</td>\n      <td>-0.745462</td>\n      <td>0.653484</td>\n      <td>0.51852</td>\n      <td>-0.526844</td>\n      <td>-0.176991</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>0.191998</td>\n      <td>0.954050</td>\n      <td>-0.147987</td>\n      <td>-0.185449</td>\n      <td>-0.077791</td>\n      <td>1.121551</td>\n      <td>-3.131278</td>\n      <td>0.51852</td>\n      <td>-0.526844</td>\n      <td>0.807080</td>\n    </tr>\n    <tr>\n      <th>117</th>\n      <td>1.112263</td>\n      <td>0.954050</td>\n      <td>-0.147987</td>\n      <td>-0.185449</td>\n      <td>-0.077791</td>\n      <td>-0.745462</td>\n      <td>0.653484</td>\n      <td>0.51852</td>\n      <td>-0.526844</td>\n      <td>-0.176991</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>113</th>\n      <td>-1.648532</td>\n      <td>-1.274739</td>\n      <td>-1.290775</td>\n      <td>-1.357153</td>\n      <td>-1.429403</td>\n      <td>2.055057</td>\n      <td>-0.608103</td>\n      <td>0.51852</td>\n      <td>-0.526844</td>\n      <td>0.807080</td>\n    </tr>\n    <tr>\n      <th>64</th>\n      <td>-1.648532</td>\n      <td>-1.274739</td>\n      <td>-1.290775</td>\n      <td>-1.357153</td>\n      <td>-1.429403</td>\n      <td>2.055057</td>\n      <td>0.653484</td>\n      <td>0.51852</td>\n      <td>0.382862</td>\n      <td>0.807080</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>-1.648532</td>\n      <td>-1.274739</td>\n      <td>-0.147987</td>\n      <td>-0.185449</td>\n      <td>-0.077791</td>\n      <td>1.121551</td>\n      <td>0.653484</td>\n      <td>0.51852</td>\n      <td>-0.526844</td>\n      <td>1.791152</td>\n    </tr>\n    <tr>\n      <th>125</th>\n      <td>0.191998</td>\n      <td>0.954050</td>\n      <td>-0.147987</td>\n      <td>-0.185449</td>\n      <td>-0.077791</td>\n      <td>-0.745462</td>\n      <td>0.653484</td>\n      <td>0.51852</td>\n      <td>-0.526844</td>\n      <td>-0.176991</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1.112263</td>\n      <td>0.954050</td>\n      <td>-0.147987</td>\n      <td>-0.185449</td>\n      <td>-0.077791</td>\n      <td>-0.745462</td>\n      <td>0.653484</td>\n      <td>0.51852</td>\n      <td>-0.526844</td>\n      <td>-0.176991</td>\n    </tr>\n  </tbody>\n</table>\n<p>139 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T19:58:01.763144500Z",
     "start_time": "2023-11-08T19:58:01.732080800Z"
    }
   },
   "id": "7c9262b7c7aa893"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T19:58:02.629547600Z",
     "start_time": "2023-11-08T19:58:02.504128100Z"
    }
   },
   "id": "2c432a147daebdc"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.9428571428571428\n",
      "==================================================\n",
      "2\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.9428571428571428\n",
      "==================================================\n",
      "3\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.9428571428571428\n",
      "==================================================\n",
      "4\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.9428571428571428\n",
      "==================================================\n",
      "5\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.9428571428571428\n",
      "==================================================\n",
      "6\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.9428571428571428\n",
      "==================================================\n",
      "7\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.9428571428571428\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 13\u001B[0m\n\u001B[0;32m      3\u001B[0m params \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mn_estimators\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m400\u001B[39m, \u001B[38;5;66;03m# 弱分类器的个数\u001B[39;00m\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_depth\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m2\u001B[39m,       \u001B[38;5;66;03m# 弱分类器（CART回归树）的最大深度\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrandom_state\u001B[39m\u001B[38;5;124m'\u001B[39m: n\n\u001B[0;32m     11\u001B[0m }\n\u001B[0;32m     12\u001B[0m clf \u001B[38;5;241m=\u001B[39m GradientBoostingClassifier(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams)\n\u001B[1;32m---> 13\u001B[0m \u001B[43mclf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28mprint\u001B[39m(n)\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28mprint\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m训练集精度:\u001B[39m\u001B[38;5;124m\"\u001B[39m)   \u001B[38;5;66;03m# 训练集精度\u001B[39;00m\n",
      "File \u001B[1;32mD:\\program\\navigator\\envs\\Tf\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:538\u001B[0m, in \u001B[0;36mBaseGradientBoosting.fit\u001B[1;34m(self, X, y, sample_weight, monitor)\u001B[0m\n\u001B[0;32m    535\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_resize_state()\n\u001B[0;32m    537\u001B[0m \u001B[38;5;66;03m# fit the boosting stages\u001B[39;00m\n\u001B[1;32m--> 538\u001B[0m n_stages \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_stages\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    539\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    540\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    541\u001B[0m \u001B[43m    \u001B[49m\u001B[43mraw_predictions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    542\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    543\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_rng\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    544\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    545\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    546\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    547\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbegin_at_stage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    548\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmonitor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    549\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    551\u001B[0m \u001B[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001B[39;00m\n\u001B[0;32m    552\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n_stages \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimators_\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]:\n",
      "File \u001B[1;32mD:\\program\\navigator\\envs\\Tf\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:615\u001B[0m, in \u001B[0;36mBaseGradientBoosting._fit_stages\u001B[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001B[0m\n\u001B[0;32m    608\u001B[0m     old_oob_score \u001B[38;5;241m=\u001B[39m loss_(\n\u001B[0;32m    609\u001B[0m         y[\u001B[38;5;241m~\u001B[39msample_mask],\n\u001B[0;32m    610\u001B[0m         raw_predictions[\u001B[38;5;241m~\u001B[39msample_mask],\n\u001B[0;32m    611\u001B[0m         sample_weight[\u001B[38;5;241m~\u001B[39msample_mask],\n\u001B[0;32m    612\u001B[0m     )\n\u001B[0;32m    614\u001B[0m \u001B[38;5;66;03m# fit next stage of trees\u001B[39;00m\n\u001B[1;32m--> 615\u001B[0m raw_predictions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_stage\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    616\u001B[0m \u001B[43m    \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    617\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    618\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    619\u001B[0m \u001B[43m    \u001B[49m\u001B[43mraw_predictions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    620\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    621\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    622\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    623\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_csc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    624\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_csr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    625\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    627\u001B[0m \u001B[38;5;66;03m# track deviance (= loss)\u001B[39;00m\n\u001B[0;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m do_oob:\n",
      "File \u001B[1;32mD:\\program\\navigator\\envs\\Tf\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:260\u001B[0m, in \u001B[0;36mBaseGradientBoosting._fit_stage\u001B[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001B[0m\n\u001B[0;32m    257\u001B[0m tree\u001B[38;5;241m.\u001B[39mfit(X, residual, sample_weight\u001B[38;5;241m=\u001B[39msample_weight, check_input\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m    259\u001B[0m \u001B[38;5;66;03m# update tree leaves\u001B[39;00m\n\u001B[1;32m--> 260\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate_terminal_regions\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    261\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtree\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtree_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    262\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    263\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    264\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresidual\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    265\u001B[0m \u001B[43m    \u001B[49m\u001B[43mraw_predictions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    266\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    267\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearning_rate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mk\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    270\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    272\u001B[0m \u001B[38;5;66;03m# add tree to ensemble\u001B[39;00m\n\u001B[0;32m    273\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimators_[i, k] \u001B[38;5;241m=\u001B[39m tree\n",
      "File \u001B[1;32mD:\\program\\navigator\\envs\\Tf\\lib\\site-packages\\sklearn\\ensemble\\_gb_losses.py:121\u001B[0m, in \u001B[0;36mLossFunction.update_terminal_regions\u001B[1;34m(self, tree, X, y, residual, raw_predictions, sample_weight, sample_mask, learning_rate, k)\u001B[0m\n\u001B[0;32m    119\u001B[0m \u001B[38;5;66;03m# update each leaf (= perform line search)\u001B[39;00m\n\u001B[0;32m    120\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m leaf \u001B[38;5;129;01min\u001B[39;00m np\u001B[38;5;241m.\u001B[39mwhere(tree\u001B[38;5;241m.\u001B[39mchildren_left \u001B[38;5;241m==\u001B[39m TREE_LEAF)[\u001B[38;5;241m0\u001B[39m]:\n\u001B[1;32m--> 121\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_update_terminal_region\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    122\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtree\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    123\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmasked_terminal_regions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    124\u001B[0m \u001B[43m        \u001B[49m\u001B[43mleaf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    125\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    126\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    127\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresidual\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    128\u001B[0m \u001B[43m        \u001B[49m\u001B[43mraw_predictions\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    129\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    130\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    132\u001B[0m \u001B[38;5;66;03m# update predictions (both in-bag and out-of-bag)\u001B[39;00m\n\u001B[0;32m    133\u001B[0m raw_predictions[:, k] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m learning_rate \u001B[38;5;241m*\u001B[39m tree\u001B[38;5;241m.\u001B[39mvalue[:, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mtake(\n\u001B[0;32m    134\u001B[0m     terminal_regions, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m\n\u001B[0;32m    135\u001B[0m )\n",
      "File \u001B[1;32mD:\\program\\navigator\\envs\\Tf\\lib\\site-packages\\sklearn\\ensemble\\_gb_losses.py:842\u001B[0m, in \u001B[0;36mMultinomialDeviance._update_terminal_region\u001B[1;34m(self, tree, terminal_regions, leaf, X, y, residual, raw_predictions, sample_weight)\u001B[0m\n\u001B[0;32m    840\u001B[0m residual \u001B[38;5;241m=\u001B[39m residual\u001B[38;5;241m.\u001B[39mtake(terminal_region, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m    841\u001B[0m y \u001B[38;5;241m=\u001B[39m y\u001B[38;5;241m.\u001B[39mtake(terminal_region, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m--> 842\u001B[0m sample_weight \u001B[38;5;241m=\u001B[39m \u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtake\u001B[49m\u001B[43m(\u001B[49m\u001B[43mterminal_region\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    844\u001B[0m numerator \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msum(sample_weight \u001B[38;5;241m*\u001B[39m residual)\n\u001B[0;32m    845\u001B[0m numerator \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mK \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mK\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "random_state = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "for n in random_state:\n",
    "    params = {\n",
    "        'n_estimators': 400, # 弱分类器的个数\n",
    "        'max_depth': 2,       # 弱分类器（CART回归树）的最大深度\n",
    "        'min_samples_split': 3, # 分裂内部节点所需的最小样本数\n",
    "        'learning_rate': 0.02,  # 学习率\n",
    "        'loss': 'deviance',\n",
    "        'subsample': 0.8,\n",
    "        'random_state': n\n",
    "    }\n",
    "    clf = GradientBoostingClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(n)\n",
    "    print (\"训练集精度:\")   # 训练集精度\n",
    "    print (clf.score(X_train, y_train))\n",
    "\n",
    "    print (\"\\n测试集精度:\")    # 测试集精度\n",
    "    print (clf.score(X_test, y_test))\n",
    "    print('=' * 50)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T19:58:11.317592300Z",
     "start_time": "2023-11-08T19:58:03.184901900Z"
    }
   },
   "id": "f1f6f63e8e244756"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def train_and_evaluate(clf, X_train, X_test, y_train, y_test):\n",
    "    clf.fit(X_train, y_train)             # 训练\n",
    "\n",
    "    print (\"训练集精度:\")   # 训练集精度\n",
    "    print (clf.score(X_train, y_train))\n",
    "\n",
    "    print (\"\\n测试集精度:\")    # 测试集精度\n",
    "    print (clf.score(X_test, y_test))\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print (\"\\n分类识别报告:\")      # 分类识别报告\n",
    "    print (metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "    # print (\"\\n混淆矩阵:\")\n",
    "    # print (metrics.confusion_matrix(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T19:58:15.069101500Z",
     "start_time": "2023-11-08T19:58:15.053482800Z"
    }
   },
   "id": "22e8ba2dd24b700d"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度:\n",
      "0.9856115107913669\n",
      "\n",
      "测试集精度:\n",
      "0.9714285714285714\n",
      "\n",
      "分类识别报告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       1.00      1.00      1.00        15\n",
      "           3       0.89      1.00      0.94         8\n",
      "           4       1.00      0.91      0.95        11\n",
      "           5       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.97        35\n",
      "   macro avg       0.97      0.98      0.97        35\n",
      "weighted avg       0.97      0.97      0.97        35\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'n_estimators': 40, # 弱分类器的个数\n",
    "    'max_depth': 2,       # 弱分类器（CART回归树）的最大深度\n",
    "    'min_samples_split': 3, # 分裂内部节点所需的最小样本数\n",
    "    'learning_rate': 0.02,  # 学习率\n",
    "    'loss': 'deviance',\n",
    "    'subsample': 0.8,\n",
    "    'random_state': 2\n",
    "}\n",
    "clf = GradientBoostingClassifier(**params)\n",
    "train_and_evaluate(clf, X_train, X_test, y_train, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T19:58:15.667283700Z",
     "start_time": "2023-11-08T19:58:15.540877500Z"
    }
   },
   "id": "50bc1693bca2ff3f"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "训练集精度:\n",
      "0.8129496402877698\n",
      "\n",
      "测试集精度:\n",
      "0.8\n",
      "= -------------------------------------------------- =\n",
      "15\n",
      "训练集精度:\n",
      "0.935251798561151\n",
      "\n",
      "测试集精度:\n",
      "0.9428571428571428\n",
      "= -------------------------------------------------- =\n",
      "20\n",
      "训练集精度:\n",
      "0.9856115107913669\n",
      "\n",
      "测试集精度:\n",
      "0.9714285714285714\n",
      "= -------------------------------------------------- =\n",
      "30\n",
      "训练集精度:\n",
      "0.9856115107913669\n",
      "\n",
      "测试集精度:\n",
      "0.9714285714285714\n",
      "= -------------------------------------------------- =\n",
      "40\n",
      "训练集精度:\n",
      "0.9856115107913669\n",
      "\n",
      "测试集精度:\n",
      "0.9714285714285714\n",
      "= -------------------------------------------------- =\n",
      "50\n",
      "训练集精度:\n",
      "0.9928057553956835\n",
      "\n",
      "测试集精度:\n",
      "0.9714285714285714\n",
      "= -------------------------------------------------- =\n",
      "79\n",
      "训练集精度:\n",
      "0.9928057553956835\n",
      "\n",
      "测试集精度:\n",
      "0.9714285714285714\n",
      "= -------------------------------------------------- =\n",
      "100\n",
      "训练集精度:\n",
      "0.9928057553956835\n",
      "\n",
      "测试集精度:\n",
      "0.9714285714285714\n",
      "= -------------------------------------------------- =\n",
      "150\n",
      "训练集精度:\n",
      "0.9928057553956835\n",
      "\n",
      "测试集精度:\n",
      "0.9428571428571428\n",
      "= -------------------------------------------------- =\n",
      "200\n",
      "训练集精度:\n",
      "0.9928057553956835\n",
      "\n",
      "测试集精度:\n",
      "0.9428571428571428\n",
      "= -------------------------------------------------- =\n",
      "300\n",
      "训练集精度:\n",
      "1.0\n",
      "\n",
      "测试集精度:\n",
      "0.9428571428571428\n",
      "= -------------------------------------------------- =\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [10, 15, 20, 30, 40, 50, 79, 100, 150, 200, 300]\n",
    "for i in n_estimators:\n",
    "    params = {\n",
    "    'n_estimators': i, # 弱分类器的个数\n",
    "    'max_depth': 2,       # 弱分类器（CART回归树）的最大深度\n",
    "    'min_samples_split': 3, # 分裂内部节点所需的最小样本数\n",
    "    'learning_rate': 0.02,  # 学习率\n",
    "    'loss': 'deviance',\n",
    "    'subsample': 0.8,\n",
    "    'random_state': 2\n",
    "}\n",
    "    clf = GradientBoostingClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(i)\n",
    "    print (\"训练集精度:\")   # 训练集精度\n",
    "    print (clf.score(X_train, y_train))\n",
    "    print (\"\\n测试集精度:\")    # 测试集精度\n",
    "    print (clf.score(X_test, y_test))\n",
    "    print('=', '-' * 50, '=')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T23:02:27.174512800Z",
     "start_time": "2023-10-29T23:02:24.530014Z"
    }
   },
   "id": "2d715803579d9dfe"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from data_pre import data_normalize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "d = pd.read_excel(r\"D:\\program\\pycharm\\model\\Data\\新训练.xlsx\", sheet_name='Sheet3')\n",
    "# X = df.iloc[:, 1:]\n",
    "# y = df.iloc[:, 0]\n",
    "data = data_normalize(d, 'WD')\n",
    "df = data.fillna_by_random()\n",
    "X = df.iloc[:, 1:]\n",
    "y = df.iloc[:, 0]\n",
    "X = data.iso(X)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "aver = X_train.mean(axis=0)\n",
    "std = X_train.std(axis=0)\n",
    "X_train = (X_train-aver)/std\n",
    "X_test = (X_test-aver)/std"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T22:41:37.641467900Z",
     "start_time": "2023-11-07T22:41:37.486432800Z"
    }
   },
   "id": "9ebba7f17ee6d5b8"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度:\n",
      "0.9928057553956835\n",
      "\n",
      "测试集精度:\n",
      "0.9714285714285714\n",
      "\n",
      "分类识别报告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       1.00      1.00      1.00        15\n",
      "           3       0.89      1.00      0.94         8\n",
      "           4       1.00      0.91      0.95        11\n",
      "           5       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.97        35\n",
      "   macro avg       0.97      0.98      0.97        35\n",
      "weighted avg       0.97      0.97      0.97        35\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def train_and_evaluate(clf, X_train, X_test, y_train, y_test):\n",
    "    clf.fit(X_train, y_train)             # 训练\n",
    "\n",
    "    print (\"训练集精度:\")   # 训练集精度\n",
    "    print (clf.score(X_train, y_train))\n",
    "\n",
    "    print (\"\\n测试集精度:\")    # 测试集精度\n",
    "    print (clf.score(X_test, y_test))\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print (\"\\n分类识别报告:\")      # 分类识别报告\n",
    "    print (metrics.classification_report(y_test, y_pred))\n",
    "params = {\n",
    "    'n_estimators': 40,\n",
    "    'max_depth': 2,\n",
    "    'min_samples_split': 3,\n",
    "    'learning_rate': 0.1,\n",
    "    'loss': 'deviance',\n",
    "    'subsample': 0.8,\n",
    "    'random_state': 2\n",
    "}\n",
    "clf = GradientBoostingClassifier(**params)\n",
    "train_and_evaluate(clf, X_train, X_test, y_train, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T21:17:59.321732200Z",
     "start_time": "2023-11-08T21:17:59.180712400Z"
    }
   },
   "id": "23d5bb0e61f9ba31"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "25e98433994c069b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
